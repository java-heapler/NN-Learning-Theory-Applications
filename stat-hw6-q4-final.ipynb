{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T22:10:22.038014Z",
     "iopub.status.busy": "2023-05-05T22:10:22.037166Z",
     "iopub.status.idle": "2023-05-05T22:10:22.067485Z",
     "shell.execute_reply": "2023-05-05T22:10:22.066159Z",
     "shell.execute_reply.started": "2023-05-05T22:10:22.037964Z"
    }
   },
   "source": [
    "# Problem 4: U CNN on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a CNN with an architecture of your own choice with three convolutional layers with max- pooling and one linear layer. Take your minibatch size 100. You may take the Adam optimizer. Use the activation function of your choice. You may take your epochs 10 or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compare the performance on your test set when you use the cross-entropy loss vs. the MSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T16:10:15.010425Z",
     "iopub.status.busy": "2023-05-06T16:10:15.010008Z",
     "iopub.status.idle": "2023-05-06T16:10:15.017116Z",
     "shell.execute_reply": "2023-05-06T16:10:15.016117Z",
     "shell.execute_reply.started": "2023-05-06T16:10:15.010393Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T16:10:16.467400Z",
     "iopub.status.busy": "2023-05-06T16:10:16.466957Z",
     "iopub.status.idle": "2023-05-06T16:10:16.481302Z",
     "shell.execute_reply": "2023-05-06T16:10:16.479884Z",
     "shell.execute_reply.started": "2023-05-06T16:10:16.467368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T22:53:56.141729Z",
     "iopub.status.busy": "2023-05-05T22:53:56.141134Z",
     "iopub.status.idle": "2023-05-05T22:59:00.116842Z",
     "shell.execute_reply": "2023-05-05T22:59:00.115676Z",
     "shell.execute_reply.started": "2023-05-05T22:53:56.141692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 14092848.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "[Epoch 1, Batch   100] loss: 2.041, accuracy: 25.300\n",
      "[Epoch 1, Batch   200] loss: 1.672, accuracy: 39.170\n",
      "[Epoch 1, Batch   300] loss: 1.558, accuracy: 44.570\n",
      "[Epoch 1, Batch   400] loss: 1.479, accuracy: 46.960\n",
      "[Epoch 1, Batch   500] loss: 1.420, accuracy: 49.600\n",
      "[Epoch 1] test loss: 1.373, accuracy: 51.120\n",
      "[Epoch 2, Batch   100] loss: 1.388, accuracy: 50.210\n",
      "[Epoch 2, Batch   200] loss: 1.338, accuracy: 51.990\n",
      "[Epoch 2, Batch   300] loss: 1.295, accuracy: 54.600\n",
      "[Epoch 2, Batch   400] loss: 1.268, accuracy: 55.050\n",
      "[Epoch 2, Batch   500] loss: 1.237, accuracy: 57.000\n",
      "[Epoch 2] test loss: 1.208, accuracy: 57.470\n",
      "[Epoch 3, Batch   100] loss: 1.186, accuracy: 58.480\n",
      "[Epoch 3, Batch   200] loss: 1.165, accuracy: 58.770\n",
      "[Epoch 3, Batch   300] loss: 1.148, accuracy: 59.880\n",
      "[Epoch 3, Batch   400] loss: 1.143, accuracy: 59.510\n",
      "[Epoch 3, Batch   500] loss: 1.145, accuracy: 60.020\n",
      "[Epoch 3] test loss: 1.162, accuracy: 59.070\n",
      "[Epoch 4, Batch   100] loss: 1.084, accuracy: 61.800\n",
      "[Epoch 4, Batch   200] loss: 1.069, accuracy: 62.830\n",
      "[Epoch 4, Batch   300] loss: 1.064, accuracy: 63.320\n",
      "[Epoch 4, Batch   400] loss: 1.040, accuracy: 63.420\n",
      "[Epoch 4, Batch   500] loss: 1.038, accuracy: 63.990\n",
      "[Epoch 4] test loss: 1.042, accuracy: 63.850\n",
      "[Epoch 5, Batch   100] loss: 0.981, accuracy: 65.550\n",
      "[Epoch 5, Batch   200] loss: 0.987, accuracy: 65.630\n",
      "[Epoch 5, Batch   300] loss: 1.001, accuracy: 65.060\n",
      "[Epoch 5, Batch   400] loss: 0.996, accuracy: 65.500\n",
      "[Epoch 5, Batch   500] loss: 0.992, accuracy: 65.410\n",
      "[Epoch 5] test loss: 0.993, accuracy: 65.680\n",
      "[Epoch 6, Batch   100] loss: 0.958, accuracy: 66.970\n",
      "[Epoch 6, Batch   200] loss: 0.931, accuracy: 67.920\n",
      "[Epoch 6, Batch   300] loss: 0.950, accuracy: 67.210\n",
      "[Epoch 6, Batch   400] loss: 0.918, accuracy: 68.530\n",
      "[Epoch 6, Batch   500] loss: 0.906, accuracy: 68.290\n",
      "[Epoch 6] test loss: 0.958, accuracy: 67.040\n",
      "[Epoch 7, Batch   100] loss: 0.873, accuracy: 69.800\n",
      "[Epoch 7, Batch   200] loss: 0.887, accuracy: 69.640\n",
      "[Epoch 7, Batch   300] loss: 0.869, accuracy: 70.210\n",
      "[Epoch 7, Batch   400] loss: 0.891, accuracy: 68.530\n",
      "[Epoch 7, Batch   500] loss: 0.885, accuracy: 69.510\n",
      "[Epoch 7] test loss: 0.943, accuracy: 67.640\n",
      "[Epoch 8, Batch   100] loss: 0.832, accuracy: 71.080\n",
      "[Epoch 8, Batch   200] loss: 0.835, accuracy: 71.110\n",
      "[Epoch 8, Batch   300] loss: 0.843, accuracy: 70.630\n",
      "[Epoch 8, Batch   400] loss: 0.847, accuracy: 70.620\n",
      "[Epoch 8, Batch   500] loss: 0.841, accuracy: 70.910\n",
      "[Epoch 8] test loss: 0.911, accuracy: 68.210\n",
      "[Epoch 9, Batch   100] loss: 0.799, accuracy: 72.730\n",
      "[Epoch 9, Batch   200] loss: 0.802, accuracy: 72.240\n",
      "[Epoch 9, Batch   300] loss: 0.799, accuracy: 71.790\n",
      "[Epoch 9, Batch   400] loss: 0.799, accuracy: 72.050\n",
      "[Epoch 9, Batch   500] loss: 0.808, accuracy: 72.270\n",
      "[Epoch 9] test loss: 0.883, accuracy: 69.820\n",
      "[Epoch 10, Batch   100] loss: 0.767, accuracy: 73.150\n",
      "[Epoch 10, Batch   200] loss: 0.779, accuracy: 72.900\n",
      "[Epoch 10, Batch   300] loss: 0.764, accuracy: 73.690\n",
      "[Epoch 10, Batch   400] loss: 0.777, accuracy: 73.330\n",
      "[Epoch 10, Batch   500] loss: 0.786, accuracy: 73.100\n",
      "[Epoch 10] test loss: 0.898, accuracy: 69.570\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# This architecture has three convolutional layers with 16, 32, and 64 output channels, \n",
    "# followed by max-pooling layers with a 2x2 kernel and stride of 2. \n",
    "# The output of the last convolutional layer is flattened and passed through a fully connected linear layer \n",
    "# with 10 output features.\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*4*4, out_features=10)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Adam optimizer, learning rate=0.001, batch size=100:\n",
    "# define the model\n",
    "model = MyCNN()\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', train=True, transform=ToTensor(), download=True)\n",
    "test_data = CIFAR10(root='./data', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# Print training accuracy after every 100 mini-batches. \n",
    "# Evaluate the model on the test set after each epoch, and print the test loss and accuracy.\n",
    "# train the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[Epoch %d, Batch %5d] loss: %.3f, accuracy: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, 100 * correct / total))\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "    \n",
    "    # evaluate on test set\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('[Epoch %d] test loss: %.3f, accuracy: %.3f' %\n",
    "          (epoch + 1, test_loss / len(test_loader), 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T16:37:00.735630Z",
     "iopub.status.busy": "2023-05-06T16:37:00.735225Z",
     "iopub.status.idle": "2023-05-06T16:42:11.281162Z",
     "shell.execute_reply": "2023-05-06T16:42:11.279875Z",
     "shell.execute_reply.started": "2023-05-06T16:37:00.735599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1, Batch   100] loss: 0.084\n",
      "[Epoch 1, Batch   200] loss: 0.076\n",
      "[Epoch 1, Batch   300] loss: 0.072\n",
      "[Epoch 1, Batch   400] loss: 0.070\n",
      "[Epoch 1, Batch   500] loss: 0.068\n",
      "[Epoch 1] test loss: 0.067, accuracy: 52.570\n",
      "[Epoch 2, Batch   100] loss: 0.066\n",
      "[Epoch 2, Batch   200] loss: 0.064\n",
      "[Epoch 2, Batch   300] loss: 0.062\n",
      "[Epoch 2, Batch   400] loss: 0.062\n",
      "[Epoch 2, Batch   500] loss: 0.062\n",
      "[Epoch 2] test loss: 0.061, accuracy: 59.810\n",
      "[Epoch 3, Batch   100] loss: 0.059\n",
      "[Epoch 3, Batch   200] loss: 0.058\n",
      "[Epoch 3, Batch   300] loss: 0.059\n",
      "[Epoch 3, Batch   400] loss: 0.058\n",
      "[Epoch 3, Batch   500] loss: 0.058\n",
      "[Epoch 3] test loss: 0.057, accuracy: 64.390\n",
      "[Epoch 4, Batch   100] loss: 0.056\n",
      "[Epoch 4, Batch   200] loss: 0.056\n",
      "[Epoch 4, Batch   300] loss: 0.055\n",
      "[Epoch 4, Batch   400] loss: 0.055\n",
      "[Epoch 4, Batch   500] loss: 0.055\n",
      "[Epoch 4] test loss: 0.055, accuracy: 65.650\n",
      "[Epoch 5, Batch   100] loss: 0.053\n",
      "[Epoch 5, Batch   200] loss: 0.053\n",
      "[Epoch 5, Batch   300] loss: 0.054\n",
      "[Epoch 5, Batch   400] loss: 0.053\n",
      "[Epoch 5, Batch   500] loss: 0.052\n",
      "[Epoch 5] test loss: 0.054, accuracy: 65.820\n",
      "[Epoch 6, Batch   100] loss: 0.052\n",
      "[Epoch 6, Batch   200] loss: 0.052\n",
      "[Epoch 6, Batch   300] loss: 0.051\n",
      "[Epoch 6, Batch   400] loss: 0.052\n",
      "[Epoch 6, Batch   500] loss: 0.051\n",
      "[Epoch 6] test loss: 0.053, accuracy: 67.500\n",
      "[Epoch 7, Batch   100] loss: 0.049\n",
      "[Epoch 7, Batch   200] loss: 0.050\n",
      "[Epoch 7, Batch   300] loss: 0.051\n",
      "[Epoch 7, Batch   400] loss: 0.050\n",
      "[Epoch 7, Batch   500] loss: 0.050\n",
      "[Epoch 7] test loss: 0.052, accuracy: 68.770\n",
      "[Epoch 8, Batch   100] loss: 0.049\n",
      "[Epoch 8, Batch   200] loss: 0.049\n",
      "[Epoch 8, Batch   300] loss: 0.049\n",
      "[Epoch 8, Batch   400] loss: 0.049\n",
      "[Epoch 8, Batch   500] loss: 0.049\n",
      "[Epoch 8] test loss: 0.051, accuracy: 69.010\n",
      "[Epoch 9, Batch   100] loss: 0.048\n",
      "[Epoch 9, Batch   200] loss: 0.048\n",
      "[Epoch 9, Batch   300] loss: 0.049\n",
      "[Epoch 9, Batch   400] loss: 0.048\n",
      "[Epoch 9, Batch   500] loss: 0.048\n",
      "[Epoch 9] test loss: 0.050, accuracy: 70.290\n",
      "[Epoch 10, Batch   100] loss: 0.047\n",
      "[Epoch 10, Batch   200] loss: 0.047\n",
      "[Epoch 10, Batch   300] loss: 0.048\n",
      "[Epoch 10, Batch   400] loss: 0.048\n",
      "[Epoch 10, Batch   500] loss: 0.048\n",
      "[Epoch 10] test loss: 0.050, accuracy: 69.980\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# modify the training loop to use one-hot encoded targets\n",
    "# define the model\n",
    "model = MyCNN()\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', train=True, transform=ToTensor(), download=True)\n",
    "test_data = CIFAR10(root='./data', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# train the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # convert labels to one-hot encoding\n",
    "        labels_onehot = nn.functional.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[Epoch %d, Batch %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        # evaluate on test set\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # convert labels to one-hot encoding\n",
    "            labels_onehot = nn.functional.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels_onehot)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('[Epoch %d] test loss: %.3f, accuracy: %.3f' %\n",
    "          (epoch + 1, test_loss / len(test_loader), 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T16:42:11.284664Z",
     "iopub.status.busy": "2023-05-06T16:42:11.283688Z",
     "iopub.status.idle": "2023-05-06T16:42:11.289007Z",
     "shell.execute_reply": "2023-05-06T16:42:11.288199Z",
     "shell.execute_reply.started": "2023-05-06T16:42:11.284609Z"
    }
   },
   "outputs": [],
   "source": [
    "# The test accuracy bottle-necked at around 70%. This is because MSE loss is typically not used for multi-class \n",
    "# classification tasks. Cross-entropy loss is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compare your models when you use Adam vs. RMSProp. You may use the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T23:20:19.381204Z",
     "iopub.status.busy": "2023-05-05T23:20:19.380642Z",
     "iopub.status.idle": "2023-05-05T23:29:48.374476Z",
     "shell.execute_reply": "2023-05-05T23:29:48.373522Z",
     "shell.execute_reply.started": "2023-05-05T23:20:19.381143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Adam, Epoch 1, Batch   100] loss: 2.052\n",
      "[Adam, Epoch 1, Batch   200] loss: 1.684\n",
      "[Adam, Epoch 1, Batch   300] loss: 1.566\n",
      "[Adam, Epoch 1, Batch   400] loss: 1.526\n",
      "[Adam, Epoch 1, Batch   500] loss: 1.475\n",
      "[Adam, Epoch 1] test loss: 1.427, accuracy: 48.390\n",
      "[Adam, Epoch 2, Batch   100] loss: 1.398\n",
      "[Adam, Epoch 2, Batch   200] loss: 1.360\n",
      "[Adam, Epoch 2, Batch   300] loss: 1.334\n",
      "[Adam, Epoch 2, Batch   400] loss: 1.293\n",
      "[Adam, Epoch 2, Batch   500] loss: 1.271\n",
      "[Adam, Epoch 2] test loss: 1.215, accuracy: 56.660\n",
      "[Adam, Epoch 3, Batch   100] loss: 1.198\n",
      "[Adam, Epoch 3, Batch   200] loss: 1.198\n",
      "[Adam, Epoch 3, Batch   300] loss: 1.193\n",
      "[Adam, Epoch 3, Batch   400] loss: 1.167\n",
      "[Adam, Epoch 3, Batch   500] loss: 1.134\n",
      "[Adam, Epoch 3] test loss: 1.124, accuracy: 60.640\n",
      "[Adam, Epoch 4, Batch   100] loss: 1.087\n",
      "[Adam, Epoch 4, Batch   200] loss: 1.087\n",
      "[Adam, Epoch 4, Batch   300] loss: 1.086\n",
      "[Adam, Epoch 4, Batch   400] loss: 1.059\n",
      "[Adam, Epoch 4, Batch   500] loss: 1.020\n",
      "[Adam, Epoch 4] test loss: 1.041, accuracy: 63.300\n",
      "[Adam, Epoch 5, Batch   100] loss: 1.012\n",
      "[Adam, Epoch 5, Batch   200] loss: 0.997\n",
      "[Adam, Epoch 5, Batch   300] loss: 0.966\n",
      "[Adam, Epoch 5, Batch   400] loss: 0.983\n",
      "[Adam, Epoch 5, Batch   500] loss: 0.984\n",
      "[Adam, Epoch 5] test loss: 0.969, accuracy: 66.530\n",
      "[Adam, Epoch 6, Batch   100] loss: 0.913\n",
      "[Adam, Epoch 6, Batch   200] loss: 0.963\n",
      "[Adam, Epoch 6, Batch   300] loss: 0.926\n",
      "[Adam, Epoch 6, Batch   400] loss: 0.924\n",
      "[Adam, Epoch 6, Batch   500] loss: 0.923\n",
      "[Adam, Epoch 6] test loss: 0.954, accuracy: 66.710\n",
      "[Adam, Epoch 7, Batch   100] loss: 0.885\n",
      "[Adam, Epoch 7, Batch   200] loss: 0.879\n",
      "[Adam, Epoch 7, Batch   300] loss: 0.905\n",
      "[Adam, Epoch 7, Batch   400] loss: 0.870\n",
      "[Adam, Epoch 7, Batch   500] loss: 0.877\n",
      "[Adam, Epoch 7] test loss: 0.917, accuracy: 68.400\n",
      "[Adam, Epoch 8, Batch   100] loss: 0.848\n",
      "[Adam, Epoch 8, Batch   200] loss: 0.858\n",
      "[Adam, Epoch 8, Batch   300] loss: 0.841\n",
      "[Adam, Epoch 8, Batch   400] loss: 0.851\n",
      "[Adam, Epoch 8, Batch   500] loss: 0.851\n",
      "[Adam, Epoch 8] test loss: 0.926, accuracy: 68.020\n",
      "[Adam, Epoch 9, Batch   100] loss: 0.813\n",
      "[Adam, Epoch 9, Batch   200] loss: 0.817\n",
      "[Adam, Epoch 9, Batch   300] loss: 0.804\n",
      "[Adam, Epoch 9, Batch   400] loss: 0.824\n",
      "[Adam, Epoch 9, Batch   500] loss: 0.803\n",
      "[Adam, Epoch 9] test loss: 0.885, accuracy: 69.450\n",
      "[Adam, Epoch 10, Batch   100] loss: 0.777\n",
      "[Adam, Epoch 10, Batch   200] loss: 0.771\n",
      "[Adam, Epoch 10, Batch   300] loss: 0.803\n",
      "[Adam, Epoch 10, Batch   400] loss: 0.785\n",
      "[Adam, Epoch 10, Batch   500] loss: 0.796\n",
      "[Adam, Epoch 10] test loss: 0.870, accuracy: 70.220\n",
      "[RMSProp, Epoch 1, Batch   100] loss: 2.053\n",
      "[RMSProp, Epoch 1, Batch   200] loss: 1.736\n",
      "[RMSProp, Epoch 1, Batch   300] loss: 1.613\n",
      "[RMSProp, Epoch 1, Batch   400] loss: 1.520\n",
      "[RMSProp, Epoch 1, Batch   500] loss: 1.494\n",
      "[RMSProp, Epoch 1] test loss: 1.482, accuracy: 46.480\n",
      "[RMSProp, Epoch 2, Batch   100] loss: 1.418\n",
      "[RMSProp, Epoch 2, Batch   200] loss: 1.384\n",
      "[RMSProp, Epoch 2, Batch   300] loss: 1.352\n",
      "[RMSProp, Epoch 2, Batch   400] loss: 1.334\n",
      "[RMSProp, Epoch 2, Batch   500] loss: 1.304\n",
      "[RMSProp, Epoch 2] test loss: 1.348, accuracy: 51.390\n",
      "[RMSProp, Epoch 3, Batch   100] loss: 1.293\n",
      "[RMSProp, Epoch 3, Batch   200] loss: 1.224\n",
      "[RMSProp, Epoch 3, Batch   300] loss: 1.204\n",
      "[RMSProp, Epoch 3, Batch   400] loss: 1.202\n",
      "[RMSProp, Epoch 3, Batch   500] loss: 1.186\n",
      "[RMSProp, Epoch 3] test loss: 1.160, accuracy: 58.940\n",
      "[RMSProp, Epoch 4, Batch   100] loss: 1.146\n",
      "[RMSProp, Epoch 4, Batch   200] loss: 1.144\n",
      "[RMSProp, Epoch 4, Batch   300] loss: 1.114\n",
      "[RMSProp, Epoch 4, Batch   400] loss: 1.112\n",
      "[RMSProp, Epoch 4, Batch   500] loss: 1.098\n",
      "[RMSProp, Epoch 4] test loss: 1.108, accuracy: 61.030\n",
      "[RMSProp, Epoch 5, Batch   100] loss: 1.068\n",
      "[RMSProp, Epoch 5, Batch   200] loss: 1.070\n",
      "[RMSProp, Epoch 5, Batch   300] loss: 1.046\n",
      "[RMSProp, Epoch 5, Batch   400] loss: 1.054\n",
      "[RMSProp, Epoch 5, Batch   500] loss: 1.026\n",
      "[RMSProp, Epoch 5] test loss: 1.068, accuracy: 62.490\n",
      "[RMSProp, Epoch 6, Batch   100] loss: 0.999\n",
      "[RMSProp, Epoch 6, Batch   200] loss: 1.018\n",
      "[RMSProp, Epoch 6, Batch   300] loss: 0.998\n",
      "[RMSProp, Epoch 6, Batch   400] loss: 0.982\n",
      "[RMSProp, Epoch 6, Batch   500] loss: 0.975\n",
      "[RMSProp, Epoch 6] test loss: 0.997, accuracy: 65.300\n",
      "[RMSProp, Epoch 7, Batch   100] loss: 0.946\n",
      "[RMSProp, Epoch 7, Batch   200] loss: 0.943\n",
      "[RMSProp, Epoch 7, Batch   300] loss: 0.946\n",
      "[RMSProp, Epoch 7, Batch   400] loss: 0.967\n",
      "[RMSProp, Epoch 7, Batch   500] loss: 0.928\n",
      "[RMSProp, Epoch 7] test loss: 0.983, accuracy: 65.960\n",
      "[RMSProp, Epoch 8, Batch   100] loss: 0.918\n",
      "[RMSProp, Epoch 8, Batch   200] loss: 0.910\n",
      "[RMSProp, Epoch 8, Batch   300] loss: 0.912\n",
      "[RMSProp, Epoch 8, Batch   400] loss: 0.901\n",
      "[RMSProp, Epoch 8, Batch   500] loss: 0.902\n",
      "[RMSProp, Epoch 8] test loss: 1.015, accuracy: 64.800\n",
      "[RMSProp, Epoch 9, Batch   100] loss: 0.865\n",
      "[RMSProp, Epoch 9, Batch   200] loss: 0.873\n",
      "[RMSProp, Epoch 9, Batch   300] loss: 0.863\n",
      "[RMSProp, Epoch 9, Batch   400] loss: 0.883\n",
      "[RMSProp, Epoch 9, Batch   500] loss: 0.878\n",
      "[RMSProp, Epoch 9] test loss: 0.944, accuracy: 67.630\n",
      "[RMSProp, Epoch 10, Batch   100] loss: 0.822\n",
      "[RMSProp, Epoch 10, Batch   200] loss: 0.825\n",
      "[RMSProp, Epoch 10, Batch   300] loss: 0.849\n",
      "[RMSProp, Epoch 10, Batch   400] loss: 0.849\n",
      "[RMSProp, Epoch 10, Batch   500] loss: 0.859\n",
      "[RMSProp, Epoch 10] test loss: 0.904, accuracy: 68.870\n",
      "Adam - test accuracy: 68.870\n",
      "RMSProp - test accuracy: 68.870\n"
     ]
    }
   ],
   "source": [
    "# define the models\n",
    "model_adam = MyCNN()\n",
    "model_rmsprop = MyCNN()\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizers\n",
    "optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001)\n",
    "optimizer_rmsprop = optim.RMSprop(model_rmsprop.parameters(), lr=0.001)\n",
    "\n",
    "# load the CIFAR-10 dataset\n",
    "train_data = CIFAR10(root='./data', train=True, transform=ToTensor(), download=True)\n",
    "test_data = CIFAR10(root='./data', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "# train the Adam model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer_adam.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model_adam(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_adam.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[Adam, Epoch %d, Batch %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # evaluate on test set\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model_adam(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('[Adam, Epoch %d] test loss: %.3f, accuracy: %.3f' %\n",
    "          (epoch + 1, test_loss / len(test_loader), 100 * correct / total))\n",
    "\n",
    "# train the RMSProp model\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer_rmsprop.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model_rmsprop(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_rmsprop.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[RMSProp, Epoch %d, Batch %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # evaluate on test set\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model_rmsprop(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('[RMSProp, Epoch %d] test loss: %.3f, accuracy: %.3f' %\n",
    "          (epoch + 1, test_loss / len(test_loader), 100 * correct / total))\n",
    "\n",
    "# print final results\n",
    "print('Adam - test accuracy: %.3f' % (100 * correct / total))\n",
    "print('RMSProp - test accuracy: %.3f' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare the performance with ReLU vs sigmoid activation with cross-entropy loss and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T15:55:49.644983Z",
     "iopub.status.busy": "2023-05-06T15:55:49.644397Z",
     "iopub.status.idle": "2023-05-06T16:02:03.260448Z",
     "shell.execute_reply": "2023-05-06T16:02:03.259491Z",
     "shell.execute_reply.started": "2023-05-06T15:55:49.644937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1, Batch   100] loss: 1.923, accuracy: 30.950\n",
      "[Epoch 1, Batch   200] loss: 1.573, accuracy: 43.080\n",
      "[Epoch 1, Batch   300] loss: 1.442, accuracy: 48.080\n",
      "[Epoch 1, Batch   400] loss: 1.389, accuracy: 50.660\n",
      "[Epoch 1, Batch   500] loss: 1.316, accuracy: 52.990\n",
      "[Epoch 1] test loss: 1.275, accuracy: 54.710\n",
      "[Epoch 2, Batch   100] loss: 1.231, accuracy: 55.770\n",
      "[Epoch 2, Batch   200] loss: 1.223, accuracy: 57.160\n",
      "[Epoch 2, Batch   300] loss: 1.179, accuracy: 58.360\n",
      "[Epoch 2, Batch   400] loss: 1.140, accuracy: 60.400\n",
      "[Epoch 2, Batch   500] loss: 1.118, accuracy: 59.980\n",
      "[Epoch 2] test loss: 1.136, accuracy: 59.750\n",
      "[Epoch 3, Batch   100] loss: 1.069, accuracy: 62.690\n",
      "[Epoch 3, Batch   200] loss: 1.045, accuracy: 63.230\n",
      "[Epoch 3, Batch   300] loss: 1.041, accuracy: 63.860\n",
      "[Epoch 3, Batch   400] loss: 0.993, accuracy: 65.470\n",
      "[Epoch 3, Batch   500] loss: 1.002, accuracy: 65.010\n",
      "[Epoch 3] test loss: 1.024, accuracy: 64.120\n",
      "[Epoch 4, Batch   100] loss: 0.942, accuracy: 67.700\n",
      "[Epoch 4, Batch   200] loss: 0.953, accuracy: 66.480\n",
      "[Epoch 4, Batch   300] loss: 0.946, accuracy: 67.370\n",
      "[Epoch 4, Batch   400] loss: 0.919, accuracy: 68.030\n",
      "[Epoch 4, Batch   500] loss: 0.905, accuracy: 68.470\n",
      "[Epoch 4] test loss: 0.937, accuracy: 67.350\n",
      "[Epoch 5, Batch   100] loss: 0.871, accuracy: 69.930\n",
      "[Epoch 5, Batch   200] loss: 0.873, accuracy: 69.990\n",
      "[Epoch 5, Batch   300] loss: 0.869, accuracy: 69.650\n",
      "[Epoch 5, Batch   400] loss: 0.840, accuracy: 71.340\n",
      "[Epoch 5, Batch   500] loss: 0.849, accuracy: 70.630\n",
      "[Epoch 5] test loss: 0.888, accuracy: 69.320\n",
      "[Epoch 6, Batch   100] loss: 0.822, accuracy: 71.470\n",
      "[Epoch 6, Batch   200] loss: 0.804, accuracy: 71.860\n",
      "[Epoch 6, Batch   300] loss: 0.804, accuracy: 72.260\n",
      "[Epoch 6, Batch   400] loss: 0.805, accuracy: 72.400\n",
      "[Epoch 6, Batch   500] loss: 0.801, accuracy: 72.500\n",
      "[Epoch 6] test loss: 0.868, accuracy: 69.940\n",
      "[Epoch 7, Batch   100] loss: 0.766, accuracy: 73.670\n",
      "[Epoch 7, Batch   200] loss: 0.760, accuracy: 74.010\n",
      "[Epoch 7, Batch   300] loss: 0.757, accuracy: 73.660\n",
      "[Epoch 7, Batch   400] loss: 0.751, accuracy: 74.440\n",
      "[Epoch 7, Batch   500] loss: 0.758, accuracy: 74.150\n",
      "[Epoch 7] test loss: 0.874, accuracy: 69.750\n",
      "[Epoch 8, Batch   100] loss: 0.707, accuracy: 76.200\n",
      "[Epoch 8, Batch   200] loss: 0.715, accuracy: 75.120\n",
      "[Epoch 8, Batch   300] loss: 0.728, accuracy: 74.540\n",
      "[Epoch 8, Batch   400] loss: 0.713, accuracy: 74.840\n",
      "[Epoch 8, Batch   500] loss: 0.730, accuracy: 74.940\n",
      "[Epoch 8] test loss: 0.838, accuracy: 70.990\n",
      "[Epoch 9, Batch   100] loss: 0.676, accuracy: 76.420\n",
      "[Epoch 9, Batch   200] loss: 0.677, accuracy: 76.570\n",
      "[Epoch 9, Batch   300] loss: 0.676, accuracy: 76.920\n",
      "[Epoch 9, Batch   400] loss: 0.701, accuracy: 76.110\n",
      "[Epoch 9, Batch   500] loss: 0.673, accuracy: 77.110\n",
      "[Epoch 9] test loss: 0.814, accuracy: 72.660\n",
      "[Epoch 10, Batch   100] loss: 0.643, accuracy: 78.020\n",
      "[Epoch 10, Batch   200] loss: 0.650, accuracy: 77.770\n",
      "[Epoch 10, Batch   300] loss: 0.665, accuracy: 76.750\n",
      "[Epoch 10, Batch   400] loss: 0.680, accuracy: 76.430\n",
      "[Epoch 10, Batch   500] loss: 0.647, accuracy: 77.560\n",
      "[Epoch 10] test loss: 0.825, accuracy: 72.390\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN architecture\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, activation):\n",
    "        super(MyCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=64*4*4, out_features=10)\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the data transforms and load the CIFAR10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Define the CNN model with ReLU activation and train it\n",
    "cnn_relu = MyCNN('relu').to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_relu.parameters())\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_relu(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[Epoch %d, Batch %5d] loss: %.3f, accuracy: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, 100 * correct_train / total_train))\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "    \n",
    "    # evaluate on test set\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = cnn_relu(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    print('[Epoch %d] test loss: %.3f, accuracy: %.3f' %\n",
    "          (epoch + 1, test_loss / len(testloader), 100 * correct_test / total_test))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Plot your training error as vs the number of epochs as for cross-entropy loss with ADam optimizer and ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T16:25:11.472191Z",
     "iopub.status.busy": "2023-05-06T16:25:11.471699Z",
     "iopub.status.idle": "2023-05-06T16:30:42.341922Z",
     "shell.execute_reply": "2023-05-06T16:30:42.340598Z",
     "shell.execute_reply.started": "2023-05-06T16:25:11.472155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss = 1.563132\n",
      "Epoch 2: training loss = 1.217679\n",
      "Epoch 3: training loss = 1.055168\n",
      "Epoch 4: training loss = 0.949653\n",
      "Epoch 5: training loss = 0.873371\n",
      "Epoch 6: training loss = 0.813927\n",
      "Epoch 7: training loss = 0.767437\n",
      "Epoch 8: training loss = 0.728658\n",
      "Epoch 9: training loss = 0.696770\n",
      "Epoch 10: training loss = 0.664112\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# epochs=10 , Adam optimizer, ReLU activation\n",
    "# Plot the training loss (y-axis) vs. of the number of epochs (x-axis)\n",
    "# Define the CNN model with ReLU activation and train it\n",
    "cnn_relu = MyCNN('relu').to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_relu.parameters())\n",
    "train_loss = []\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_relu(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    train_loss.append(running_loss / len(trainloader))\n",
    "    print('Epoch %d: training loss = %f' % (epoch + 1, train_loss[-1]))\n",
    "\n",
    "# Plot the training loss as a function of the number of epochs\n",
    "plt.plot(range(10), train_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training loss')\n",
    "plt.title('Training loss as a function of the number of epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For part 4 of the problem show the last convolutional layers as images for a single sample. Do you get anything interpretable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T16:35:18.780057Z",
     "iopub.status.busy": "2023-05-06T16:35:18.779632Z",
     "iopub.status.idle": "2023-05-06T16:35:20.883937Z",
     "shell.execute_reply": "2023-05-06T16:35:20.882466Z",
     "shell.execute_reply.started": "2023-05-06T16:35:18.780025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the CNN model with ReLU activation and extract the last convolutional layers\n",
    "cnn_relu = MyCNN('relu').to(device)\n",
    "cnn_layers = nn.Sequential(*list(cnn_relu.children())[:-2])\n",
    "\n",
    "# Retrieve a single sample from the test set\n",
    "sample, label = next(iter(testloader))\n",
    "sample = sample.to(device)\n",
    "label = label.to(device)\n",
    "\n",
    "# Apply the CNN layers to the sample and get the output of the last convolutional layers\n",
    "features = cnn_layers(sample)\n",
    "features_np = features.cpu().detach().numpy()\n",
    "\n",
    "# Plot the output of the last convolutional layers as images\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        axs[i, j].imshow(features_np[0, i*8+j, :, :], cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# The output of the last convolutional layers is not interpretable, as it represents a high-level feature representation of \n",
    "# the input image. However, it can give us some insights into what the CNN has learned to extract from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
